'use client'

import { useState, useEffect, useRef, useCallback } from 'react'
import { ScreenCaptureMode } from '@/lib/types'

interface UseProctoringOptions {
  camera: boolean
  audio: boolean
  screen: boolean
  screenMode?: ScreenCaptureMode
  onCameraBlack?: () => void // Callback quando c√¢mera ficar preta
  onCameraRestored?: () => void // Callback quando c√¢mera voltar ao normal
}

export function useProctoring({
  camera,
  audio,
  screen,
  screenMode = 'window',
  onCameraBlack,
  onCameraRestored,
}: UseProctoringOptions) {
  const [cameraStream, setCameraStream] = useState<MediaStream | null>(null)
  const [audioStream, setAudioStream] = useState<MediaStream | null>(null)
  const [screenStream, setScreenStream] = useState<MediaStream | null>(null)
  const [error, setError] = useState<string | null>(null)
  const [isBlackCamera, setIsBlackCamera] = useState(false)
  const consecutiveBlackFrames = useRef(0) // Contador de frames consecutivos detectados como preto

  const videoRef = useRef<HTMLVideoElement | null>(null)
  const canvasRef = useRef<HTMLCanvasElement | null>(null)
  const blackCheckIntervalRef = useRef<NodeJS.Timeout | null>(null)

  // Inicializar captura de m√≠dia
  const initializeMedia = useCallback(async () => {
    setError(null)

    try {
      // Capturar c√¢mera e/ou √°udio
      if (camera || audio) {
        const constraints: MediaStreamConstraints = {
          video: camera ? { width: 640, height: 480 } : false,
          audio: audio,
        }

        const stream = await navigator.mediaDevices.getUserMedia(constraints)

        if (camera) {
          setCameraStream(stream)
        }
        if (audio && !camera) {
          setAudioStream(stream)
        }
      }

      // Capturar tela
      if (screen) {
        const displayConstraints: DisplayMediaStreamOptions = {
          video: {
            // @ts-ignore - displaySurface n√£o est√° nos types oficiais
            displaySurface: screenMode === 'window' ? 'window' : 'monitor',
          } as MediaTrackConstraints,
          audio: false,
        }

        const screenMediaStream = await navigator.mediaDevices.getDisplayMedia(displayConstraints)
        setScreenStream(screenMediaStream)

        // Detectar quando o usu√°rio parar o compartilhamento
        screenMediaStream.getVideoTracks()[0].addEventListener('ended', () => {
          setError('Compartilhamento de tela foi interrompido')
          setScreenStream(null)
        })
      }

      return true
    } catch (err: any) {
      console.error('Erro ao capturar m√≠dia:', err)
      let errorMessage = 'Erro ao acessar dispositivos de captura'

      if (err.name === 'NotAllowedError') {
        errorMessage = 'Permiss√£o negada. Voc√™ precisa autorizar o acesso para continuar.'
      } else if (err.name === 'NotFoundError') {
        errorMessage = 'Dispositivo n√£o encontrado. Verifique se sua c√¢mera/microfone est√° conectado.'
      } else if (err.name === 'NotReadableError') {
        errorMessage = 'Dispositivo est√° sendo usado por outro aplicativo.'
      }

      setError(errorMessage)
      return false
    }
  }, [camera, audio, screen, screenMode])

  // Detectar c√¢mera preta
  const checkBlackCamera = useCallback(() => {
    if (!cameraStream || !videoRef.current || !canvasRef.current) return

    const video = videoRef.current
    const canvas = canvasRef.current
    const ctx = canvas.getContext('2d')

    if (!ctx) return

    // Configurar canvas
    canvas.width = video.videoWidth || 640
    canvas.height = video.videoHeight || 480

    // Se v√≠deo ainda n√£o est√° pronto, n√£o verificar
    if (canvas.width === 0 || canvas.height === 0) return

    // Capturar frame atual
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height)
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height)
    const pixels = imageData.data

    // Calcular m√©dia de brilho E vari√¢ncia dos pixels
    let totalBrightness = 0
    let validPixels = 0

    for (let i = 0; i < pixels.length; i += 4) {
      const r = pixels[i]
      const g = pixels[i + 1]
      const b = pixels[i + 2]
      const brightness = (r + g + b) / 3
      totalBrightness += brightness
      validPixels++
    }

    const avgBrightness = totalBrightness / validPixels

    // Calcular vari√¢ncia (desvio padr√£o) para detectar imagem est√°tica
    let variance = 0
    for (let i = 0; i < pixels.length; i += 4) {
      const r = pixels[i]
      const g = pixels[i + 1]
      const b = pixels[i + 2]
      const brightness = (r + g + b) / 3
      variance += Math.pow(brightness - avgBrightness, 2)
    }
    variance = variance / validPixels
    const stdDev = Math.sqrt(variance)

    // Considera√ß√µes para c√¢mera preta/bloqueada (EXTREMAMENTE rigoroso para evitar falsos positivos):
    // DETEC√á√ÉO (ultra rigorosa):
    //   - Brilho EXTREMO (< 2 ou > 253) E vari√¢ncia PRATICAMENTE ZERO (< 0.3)
    //   - Precisa 5 VERIFICA√á√ïES CONSECUTIVAS (10 segundos) para confirmar
    // RECUPERA√á√ÉO (muito tolerante):
    //   - Brilho > 5 e < 250 OU qualquer vari√¢ncia > 1
    // Isso praticamente elimina falsos positivos enquanto ainda detecta c√¢mera tampada

    const isVeryDark = avgBrightness < 2
    const isVeryBright = avgBrightness > 253
    const isAlmostZeroVariance = stdDev < 0.3

    // Para detectar como BLOQUEADA: ultra rigoroso
    const currentFrameIsBlack = (isVeryDark || isVeryBright) && isAlmostZeroVariance

    // Para detectar como RECUPERADA: muito tolerante (qualquer sinal m√≠nimo de vida)
    const hasNormalBrightness = avgBrightness > 5 && avgBrightness < 250
    const hasAnyMovement = stdDev > 1
    const cameraIsWorking = hasNormalBrightness || hasAnyMovement

    // Debug detalhado
    console.log('[CAMERA DEBUG]', {
      avgBrightness: avgBrightness.toFixed(2),
      stdDev: stdDev.toFixed(2),
      isVeryDark,
      isVeryBright,
      isAlmostZeroVariance,
      currentFrameIsBlack,
      hasNormalBrightness,
      hasAnyMovement,
      cameraIsWorking,
      isBlackCamera,
      consecutiveBlackFrames: consecutiveBlackFrames.current,
      threshold: '5 frames necess√°rios'
    })

    // L√≥gica de confirma√ß√£o consecutiva para DETEC√á√ÉO (agora precisa de 5 verifica√ß√µes = 10 segundos)
    if (currentFrameIsBlack) {
      consecutiveBlackFrames.current++

      // S√≥ ativa aviso ap√≥s 5 verifica√ß√µes consecutivas (10 segundos)
      if (consecutiveBlackFrames.current >= 5 && !isBlackCamera) {
        setIsBlackCamera(true)
        onCameraBlack?.()
        console.log('[CAMERA DEBUG] üö® C√ÇMERA BLOQUEADA CONFIRMADA (5 verifica√ß√µes consecutivas = 10 segundos)')
      }
    } else {
      // Frame n√£o √© completamente preto - resetar contador
      if (consecutiveBlackFrames.current > 0) {
        console.log('[CAMERA DEBUG] ‚ö†Ô∏è Frame OK detectado - resetando contador (estava em', consecutiveBlackFrames.current, ')')
      }
      consecutiveBlackFrames.current = 0
    }

    // L√≥gica IMEDIATA para RECUPERA√á√ÉO - n√£o precisa esperar m√∫ltiplas verifica√ß√µes
    if (isBlackCamera && cameraIsWorking) {
      console.log('[CAMERA DEBUG] ‚úÖ C√ÇMERA RECUPERADA - Voltando √† prova imediatamente')
      setIsBlackCamera(false)
      onCameraRestored?.()
      consecutiveBlackFrames.current = 0
    }
  }, [cameraStream, isBlackCamera, onCameraBlack, onCameraRestored])

  // Iniciar verifica√ß√£o de c√¢mera preta
  useEffect(() => {
    if (camera && cameraStream && videoRef.current) {
      // Verificar a cada 2 segundos
      blackCheckIntervalRef.current = setInterval(checkBlackCamera, 2000)

      return () => {
        if (blackCheckIntervalRef.current) {
          clearInterval(blackCheckIntervalRef.current)
        }
      }
    }
  }, [camera, cameraStream, checkBlackCamera])

  // Atualizar v√≠deo quando stream mudar
  useEffect(() => {
    if (cameraStream && videoRef.current) {
      videoRef.current.srcObject = cameraStream
    }
  }, [cameraStream])

  // Cleanup ao desmontar
  const cleanup = useCallback(() => {
    if (cameraStream) {
      cameraStream.getTracks().forEach(track => track.stop())
      setCameraStream(null)
    }
    if (audioStream) {
      audioStream.getTracks().forEach(track => track.stop())
      setAudioStream(null)
    }
    if (screenStream) {
      screenStream.getTracks().forEach(track => track.stop())
      setScreenStream(null)
    }
    if (blackCheckIntervalRef.current) {
      clearInterval(blackCheckIntervalRef.current)
    }
  }, [cameraStream, audioStream, screenStream])

  useEffect(() => {
    return cleanup
  }, [cleanup])

  return {
    cameraStream,
    audioStream,
    screenStream,
    error,
    isBlackCamera,
    initializeMedia,
    cleanup,
    videoRef,
    canvasRef,
  }
}
