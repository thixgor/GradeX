'use client'

import { useState, useEffect, useRef, useCallback } from 'react'
import { ScreenCaptureMode } from '@/lib/types'

interface UseProctoringOptions {
  camera: boolean
  audio: boolean
  screen: boolean
  screenMode?: ScreenCaptureMode
  onCameraBlack?: () => void // Callback quando c√¢mera ficar preta
  onCameraRestored?: () => void // Callback quando c√¢mera voltar ao normal
}

export function useProctoring({
  camera,
  audio,
  screen,
  screenMode = 'window',
  onCameraBlack,
  onCameraRestored,
}: UseProctoringOptions) {
  const [cameraStream, setCameraStream] = useState<MediaStream | null>(null)
  const [audioStream, setAudioStream] = useState<MediaStream | null>(null)
  const [screenStream, setScreenStream] = useState<MediaStream | null>(null)
  const [error, setError] = useState<string | null>(null)
  const [isBlackCamera, setIsBlackCamera] = useState(false)
  const consecutiveBlackFrames = useRef(0) // Contador de frames consecutivos detectados como preto

  const videoRef = useRef<HTMLVideoElement | null>(null)
  const canvasRef = useRef<HTMLCanvasElement | null>(null)
  const blackCheckIntervalRef = useRef<NodeJS.Timeout | null>(null)

  // Inicializar captura de m√≠dia
  const initializeMedia = useCallback(async () => {
    setError(null)

    try {
      // Capturar c√¢mera e/ou √°udio
      if (camera || audio) {
        const constraints: MediaStreamConstraints = {
          video: camera ? { width: 640, height: 480 } : false,
          audio: audio,
        }

        const stream = await navigator.mediaDevices.getUserMedia(constraints)

        if (camera) {
          setCameraStream(stream)
        }
        if (audio && !camera) {
          setAudioStream(stream)
        }
      }

      // Capturar tela
      if (screen) {
        const displayConstraints: DisplayMediaStreamOptions = {
          video: {
            // @ts-ignore - displaySurface n√£o est√° nos types oficiais
            displaySurface: screenMode === 'window' ? 'window' : 'monitor',
          } as MediaTrackConstraints,
          audio: false,
        }

        const screenMediaStream = await navigator.mediaDevices.getDisplayMedia(displayConstraints)
        setScreenStream(screenMediaStream)

        // Detectar quando o usu√°rio parar o compartilhamento
        screenMediaStream.getVideoTracks()[0].addEventListener('ended', () => {
          setError('Compartilhamento de tela foi interrompido')
          setScreenStream(null)
        })
      }

      return true
    } catch (err: any) {
      console.error('Erro ao capturar m√≠dia:', err)
      let errorMessage = 'Erro ao acessar dispositivos de captura'

      if (err.name === 'NotAllowedError') {
        errorMessage = 'Permiss√£o negada. Voc√™ precisa autorizar o acesso para continuar.'
      } else if (err.name === 'NotFoundError') {
        errorMessage = 'Dispositivo n√£o encontrado. Verifique se sua c√¢mera/microfone est√° conectado.'
      } else if (err.name === 'NotReadableError') {
        errorMessage = 'Dispositivo est√° sendo usado por outro aplicativo.'
      }

      setError(errorMessage)
      return false
    }
  }, [camera, audio, screen, screenMode])

  // Detectar c√¢mera preta - NOVA ABORDAGEM: verificar elemento visual renderizado
  const checkBlackCamera = useCallback(() => {
    if (!cameraStream || !videoRef.current || !canvasRef.current) return

    const video = videoRef.current
    const canvas = canvasRef.current
    const ctx = canvas.getContext('2d')

    if (!ctx) return

    // Usar dimens√µes REAIS do elemento renderizado (192x144 = w-48 h-36)
    const width = 192
    const height = 144
    canvas.width = width
    canvas.height = height

    try {
      // Capturar o que est√° sendo EXIBIDO no elemento de v√≠deo
      ctx.drawImage(video, 0, 0, width, height)
      const imageData = ctx.getImageData(0, 0, width, height)
      const pixels = imageData.data

      // Calcular m√©dia de brilho
      let totalBrightness = 0
      let validPixels = 0

      for (let i = 0; i < pixels.length; i += 4) {
        const r = pixels[i]
        const g = pixels[i + 1]
        const b = pixels[i + 2]
        const brightness = (r + g + b) / 3
        totalBrightness += brightness
        validPixels++
      }

      const avgBrightness = totalBrightness / validPixels

      // Calcular vari√¢ncia para detectar movimento
      let variance = 0
      for (let i = 0; i < pixels.length; i += 4) {
        const r = pixels[i]
        const g = pixels[i + 1]
        const b = pixels[i + 2]
        const brightness = (r + g + b) / 3
        variance += Math.pow(brightness - avgBrightness, 2)
      }
      variance = variance / validPixels
      const stdDev = Math.sqrt(variance)

      // NOVA L√ìGICA: Apenas detecta como preta se for OBVIAMENTE preta
      // - Brilho QUASE ZERO (< 5) - praticamente nenhum pixel aceso
      // - E vari√¢ncia ZERO ABSOLUTO (< 0.1) - imagem completamente congelada
      // - Precisa 8 VERIFICA√á√ïES CONSECUTIVAS (16 segundos)

      const isCompletelyBlack = avgBrightness < 5
      const isCompletelyStatic = stdDev < 0.1

      const currentFrameIsBlack = isCompletelyBlack && isCompletelyStatic

      // Para recupera√ß√£o: qualquer sinal de vida
      const cameraIsWorking = avgBrightness >= 10 || stdDev >= 0.5

      // Debug
      console.log('[CAMERA DEBUG]', {
        avgBrightness: avgBrightness.toFixed(2),
        stdDev: stdDev.toFixed(2),
        isCompletelyBlack,
        isCompletelyStatic,
        currentFrameIsBlack,
        cameraIsWorking,
        isBlackCamera,
        consecutiveBlackFrames: consecutiveBlackFrames.current,
        threshold: '8 frames = 16 segundos'
      })

      // L√≥gica de confirma√ß√£o - precisa 8 verifica√ß√µes consecutivas (16 segundos)
      if (currentFrameIsBlack) {
        consecutiveBlackFrames.current++

        if (consecutiveBlackFrames.current >= 8 && !isBlackCamera) {
          setIsBlackCamera(true)
          onCameraBlack?.()
          console.log('[CAMERA DEBUG] üö® C√ÇMERA BLOQUEADA (8 verifica√ß√µes consecutivas = 16 segundos)')
        }
      } else {
        if (consecutiveBlackFrames.current > 0) {
          console.log('[CAMERA DEBUG] ‚úÖ Frame OK - resetando contador (estava em', consecutiveBlackFrames.current, ')')
        }
        consecutiveBlackFrames.current = 0
      }

      // Recupera√ß√£o imediata
      if (isBlackCamera && cameraIsWorking) {
        console.log('[CAMERA DEBUG] ‚úÖ C√ÇMERA RECUPERADA')
        setIsBlackCamera(false)
        onCameraRestored?.()
        consecutiveBlackFrames.current = 0
      }
    } catch (error) {
      console.error('[CAMERA DEBUG] Erro ao capturar frame:', error)
    }
  }, [cameraStream, isBlackCamera, onCameraBlack, onCameraRestored])

  // Iniciar verifica√ß√£o de c√¢mera preta
  useEffect(() => {
    if (camera && cameraStream && videoRef.current) {
      // Verificar a cada 2 segundos
      blackCheckIntervalRef.current = setInterval(checkBlackCamera, 2000)

      return () => {
        if (blackCheckIntervalRef.current) {
          clearInterval(blackCheckIntervalRef.current)
        }
      }
    }
  }, [camera, cameraStream, checkBlackCamera])

  // Atualizar v√≠deo quando stream mudar
  useEffect(() => {
    if (cameraStream && videoRef.current) {
      videoRef.current.srcObject = cameraStream
    }
  }, [cameraStream])

  // Cleanup ao desmontar
  const cleanup = useCallback(() => {
    if (cameraStream) {
      cameraStream.getTracks().forEach(track => track.stop())
      setCameraStream(null)
    }
    if (audioStream) {
      audioStream.getTracks().forEach(track => track.stop())
      setAudioStream(null)
    }
    if (screenStream) {
      screenStream.getTracks().forEach(track => track.stop())
      setScreenStream(null)
    }
    if (blackCheckIntervalRef.current) {
      clearInterval(blackCheckIntervalRef.current)
    }
  }, [cameraStream, audioStream, screenStream])

  useEffect(() => {
    return cleanup
  }, [cleanup])

  return {
    cameraStream,
    audioStream,
    screenStream,
    error,
    isBlackCamera,
    initializeMedia,
    cleanup,
    videoRef,
    canvasRef,
  }
}
